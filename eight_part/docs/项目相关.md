# kv存储

# 云存储
## JWT详解
1. Session

Session的使用过程是怎样的？

- 用户进行登录时，提交包含用户名和密码的表大，放入HTTP请求报文中；
- 服务器进行验证，如果正确则将用户信息存储到Redis中，在Redis中的Key就是sessionID；
- 服务器返回的响应报文的首部包含这个SessionID，浏览器将其保存到Cookie中；
- 之后的每一次请求，都会将Cookie携带的SessionID发送给服务器，服务器根据SessionID查找Redis中的用户信息。

2. Token

Token的使用过程是怎样的？

- 客户端使用用户名和密码请求登录；
- 服务端收到请求，验证用户名和密码；
- 验证成功后，服务端会签发一个Token，再将Token返回给客户端；
- 客户端收到Token后将其存储起来，比如放入Cookie中；
- 客户端每次向服务端请求资源时需要携带这个Token，可以在Cookie或者Token中携带；
- 服务端收到请求，需要验证客户端请求中携带的Token；
- 验证成功后，服务端会从Token中获取用户的相关信息，并进行相关操作。


> Token对比Session的优点
> 
> **无状态**：Token是无状态的，而Session需要维护服务器的状态信息。这使得Token更容易在分布式系统和负载均衡器中进行管理；
>
> **扩展性**：由于Token的无状态，可以将Token轻松集成到API、移动应用程序等不同系统中；
>
> **安全性**：Token可以防止CSRF（跨站请求伪造）攻击，因为Token不包含用户名和密码，所以不能被这些攻击方式利用；
>
> **性能**：Session需要在服务端维护状态信息，可能会影响性能；Token可以在客户端进行验证和授权，减少了对服务器的负载；


3. 什么是JWT

JWT的全称是`Json Web Token`，本质是字符串，是Token的一种具体实现方式。

**JWT的认证流程**
- JWT生成
  - 前端通过Web表单将用户名和密码发送到后端的接口，这个过程一般是POST请求。可以通过SSL加密传输，防止敏感信息嗅探；
  - 后端核对用户名和密码成功后，**将包含用户信息的数据作为JWT的Payload**，与**JWT Header**分别进行Base64编码拼接后签名，形成一个JWT Token，形成的JWT Token就是一个形如`lll.zzz.xxx`的字符串；
  - 后端将JWT Token字符串作为登陆成功的结果返回给前端。前端可以将返回的结果保存在浏览器中，退出时删除保存的JWT Token即可。
- 请求
  - 前端在每次请求时将JWT Token放入HTTP请求头的`Authorization`属性中（解决XSS和XSRF问题）；
  - 后端检查前端传过来的JWT Token，验证有效性，比如检查签名是否正确、是否过期、token的接收方是否是自己等；
  - 验证通过后，后端解析出JWT Token包含的用户信息，进行其他逻辑操作，返回结果。

![](./Pasted%20image%2020240515222455.png)

4. 为什么使用JWT？

**传统Session的弊端**
- 服务端状态管理：需要在服务端维护用户的状态信息，可能会增加服务器的负担和复杂度；
- 分布式环境下的问题：跨节点Session；
- 扩展性差：Session跨域传递问题；
- CSRF攻击：Session认证容易受到CSRF攻击，攻击者可以通过伪造请求来获取用户的会话信息；
- 跨域问题：由于Session是基于Cookie实现的，而Cookie在跨域请求时会受到浏览器的同源策略限制，可能会导致某些跨域场景下无法正常使用。
- 占用带宽：每次请求都要携带Session ID等相关信息，增加了请求头的大小，占用了带宽，并且可能会影响网络性能。

**JWT的好处**
- 无状态
- 可拓展性：基于JSON
- 安全性：签名和加密
- 可定制性：可以根据业务需求自定义

**JWT的缺点**
- 信息泄露：base64编码不安全
- 不可撤销性：一经签发不可撤销
- 大小限制：网络传输和存储方面性能损失
- 安全更新：如果需要更新JWT中的某些信息，例如访问权限、过期时间等，需要重新签发一个新的JWT。但是，这可能会导致之前签发的JWT仍然有效，从而导致安全性问题。

5. JWT结构

JWT由三部分组成分别是Header、Payload、Signature，每个部分都使用base64编码，使用`.`连接，形成一个完成的JWT字符串。

- Header：描述JWT的元数据，包括类型（`JWT`）和使用的签名算法（`HS256`）。
- Payload：有效载荷部分，是JWT的主体内容，也是一个JSON对象。有7个字段可以选择。如发行人、到期时间、主题、用户、发布时间、JWT ID等，还可以定义一些私有字段；默认情况下JWT是未加密的，拿到JWT字符串后可以转换为原本的JSON数据，任何人都可以解读内容。JWT只适合在网络中传输一些非敏感信息。
- Signature：使用Header中的指定签名算法对编码后的header和payload数据进行签名，并且生成哈希。首先需要指定一个密钥，**存储在服务器中**，不能向用户公开。使用header中的签名算法生成签名，计算出签名哈希后，JWT头，有效载荷和签名哈希的三个部分组合成一个字符串，每个部分用.分隔，就构成整个JWT对象。

服务端如何解析：
- header和payload可以直接利用base64解码出原文，从header中获取哈希签名的算法，从payload中获取有效数据
- signature由于使用了不可逆的加密算法，无法解码出原文，它的作用是校验token有没有被篡改。服务端获取header中的加密算法之后，利用该算法加上secretKey对header、payload进行加密，比对加密后的数据和客户端发送过来的是否一致。注意secretKey只能保存在服务端，而且对于不同的加密算法其含义有所不同，一般对于MD5类型的摘要加密算法，secretKey实际上代表的是盐值。

6. JWT的种类
JWT（JSON Web Token）根据用途和属性的不同，可以分为以下几种：
- JWS：JSON Web Signature，用于验证消息的完整性和来源。JWS包含Header、Payload和Signature三个部分，其中Signature是通过指定算法生成的，用于验证消息是否被篡改。
- JWE：JSON Web Encryption，用于对消息进行加密。JWE包含Header、Payload和Encryption三个部分，其中Encryption使用指定算法对消息进行加密，以保证机密性。
- JWK：JSON Web Key，用于描述用于加密、解密或签名JWT的公钥和私钥信息。JWK通常包括key type、key id、public key等属性。
- JWA：JSON Web Algorithm，用于描述JWT所支持的加密、解密和签名算法，例如HMAC、RSA、AES等。
需要注意的是，这些JWT的种类并不是相互独立的，它们可以结合使用来实现更强大的功能，例如使用JWS和JWE来同时保证消息的完整性、机密性和来源可信度。

```go
package utils

import (
	"errors"
	"fmt"
	"time"

	"github.com/golang-jwt/jwt/v4"  // 调包
)

type MyClaims struct {
	jwt.RegisteredClaims
	ID    int64
	State string `json:"state"`
}

var accessSecret = []byte("go-zero-netdisk")  // 指定accessSecret
var refreshSecret = []byte("114514")          // 指定refreshSecret

// GetToken 获取 accessToken 和 refreshToken
func GetToken(id int64, state string) (string, string) {
	// 临时访问令牌
	accessToken := jwt.NewWithClaims(jwt.SigningMethodHS256, MyClaims{
		RegisteredClaims: jwt.RegisteredClaims{ // Payload部分
			Issuer:    "accessToken", // 发行人
			IssuedAt:  jwt.NewNumericDate(time.Now()),  // 签发时间
			ExpiresAt: jwt.NewNumericDate(time.Now().Add(3 * time.Hour)), // 过期时间
		},
		ID:    id,
		State: state,
	})

	// 刷新令牌
	refreshToken := jwt.NewWithClaims(jwt.SigningMethodHS256, MyClaims{
		RegisteredClaims: jwt.RegisteredClaims{
			Issuer:    "refreshToken",
			IssuedAt:  jwt.NewNumericDate(time.Now()),
			ExpiresAt: jwt.NewNumericDate(time.Now().Add(24 * 30 * time.Hour)),
		},
		ID:    id,
		State: state,
	})

	accessTokenSigned, err := accessToken.SignedString(accessSecret)   // 签发accessTokenSigned
	if err != nil {
		fmt.Println("获取Token失败，Secret错误")
		return "", ""
	}
	refreshTokenSigned, err := refreshToken.SignedString(refreshSecret)
	if err != nil {
		fmt.Println("获取Token失败，Secret错误")
		return "", ""
	}
  // 生成访问令牌和刷新令牌
	return accessTokenSigned, refreshTokenSigned
}

// ParseToken 解析token
func ParseToken(accessTokenString, refreshTokenString string) (*MyClaims, bool, error) {
	fmt.Println("Parsing Token...")
	// 解析访问令牌
	accessToken, err := jwt.ParseWithClaims(accessTokenString, &MyClaims{}, func(token *jwt.Token) (interface{}, error) {
		return accessSecret, nil
	})
	if err != nil {
		return nil, false, err
	}
	if claims, ok := accessToken.Claims.(*MyClaims); ok && accessToken.Valid {
		return claims, false, nil
	}

	fmt.Println("Refresh Token")
	refreshToken, err := jwt.ParseWithClaims(refreshTokenString, &MyClaims{}, func(token *jwt.Token) (interface{}, error) {
		return refreshSecret, nil
	})
	if err != nil {
		return nil, false, err
	}
	if claims, ok := refreshToken.Claims.(*MyClaims); ok && refreshToken.Valid {
		return claims, false, nil
	}

	return nil, false, errors.New("invalid token")
}

func (m *JWTMiddleware) Handle(next http.HandlerFunc) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		// TODO generate middleware implement function, delete after code implementation
		// JWTAuthMiddleware Implementation
    // 获取Authorization部分数据
		authHeader := r.Header.Get("Authorization")
		if authHeader == "" { // 判断请求是否为空
			w.WriteHeader(http.StatusBadRequest)
			err, _ := json.Marshal(errorx.NewCodeError(uint32(errorx.ErrHeaderNil), "请求头中auth为空"))
			w.Write(err)
			return
		}
		parts := strings.Split(authHeader, " ") // 获取parts
		if !(len(parts) == 3 && parts[0] == "Bearer") {
			w.WriteHeader(http.StatusBadRequest)
			err, _ := json.Marshal(errorx.NewCodeError(uint32(errorx.ErrHeaderFormat), "请求头格式错误"))
			w.Write(err)
			return
		}
		// 解析token
		claims, isExpire, err := utils.ParseToken(parts[1], parts[2])
		if err != nil {
			w.WriteHeader(http.StatusUnauthorized)
			err, _ := json.Marshal(errorx.NewCodeError(uint32(errorx.ErrTokenProve), "token验证错误"))
			w.Write(err)
			return
		}
		if isExpire {
			parts[1], parts[2] = utils.GetToken(claims.ID, claims.State)
			w.Header().Set("Authorization", fmt.Sprintf("Bearer %s %s", parts[1], parts[2]))
		}
		r = r.WithContext(context.WithValue(r.Context(), UserIDKey, claims.ID))
		// Passthrough to next handler if need
		next(w, r)
	}
}

```

7. 第三方系统如QQ接入后，如何构建JWT？

QQ扫码登录采用的是OAuth2.0协议，接入QQ即通过QQ获取用户信息，避免输入用户名和密码。然后根据QQ获取的用户信息进行用户鉴权和管理。

> **OAuth登录的流程**
> 
> OAuth在客户端client和服务提供商之间，设置了一个授权层`authorization layer`，客户端不能直接登录服务提供商，只能登录授权层，以此将用户与客户端区分开来。客户端登录授权层使用的令牌token，与用户密码不同，用户在登录时，指定令牌的权限和有效期。
> 
> 客户端登录授权层后，服务提供商根据令牌层的权限范围和有效期，向客户端开放用户存储的资料。
>
> **运行流程**
> 
> 1. 用户请求Resource owner，请求Authorization Request，返回Authorization Grant；
> 2. 用户请求Authorization Server（授权服务器），请求Authorization Grant，返回Access Token；
> 3. 用户根据Access Token访问Resource Server，返回Protected Resource。实际上在这里需要获取的是第三方id，根据第三方id再在user表中查找是否授权。

user表中包含了用户的基本信息，如ID、用户名、昵称等；
user_auth表中存储了用户的认证信息，包括创建时间、更新时间、用户ID、第三方平台的唯一ID`privider_id`和平台类型。

这两张表通过user_id字段建立关系。

如何登录：从user_auth表开始，通过provider和provider_id找到对应的user_id，然后使用这个 user_id 在 user 表中找到用户的详细信息。

8. OAuth2.0登录逻辑（代码讲解）
- 申请appid和appkey
  - appid：应用的唯一id，在OAuth认证过程中，appid的值即为oauth_consumer_key的值；
  - appkey：appid对应的密钥，访问用户资源时验证应用的合法性，在oauth2.0认证中，appkey的值即为oauth_consumer_secret的值。
- 授权流程
  - 采用OAuth2.0协议，QQ登录采用的授权类型为`authorization_code`，即**授权码**模式。
  - 用户访问第三方应用，qq返回一个授权的code；
  - 通过授权的code向qq服务器获取token，根据token即可访问具体的api接口。

**代码详解**

- 获取Code：自动打开网页，可以点击QQ号进行登录，或者扫码登录。
```go
func GetAuthCode(w http.ResponseWriter, r *http.Request) {
    params := url.Values{}
    params.Add("response_type", "code")
    params.Add("client_id", AppId)  // 将AppID传入URL
    params.Add("state", "test")
    str := fmt.Sprintf("%s&redirect_uri=%s", params.Encode(), redirectURI)
    loginURL := fmt.Sprintf("%s?%s", "https://graph.qq.com/oauth2.0/authorize", str)

    http.Redirect(w, r, loginURL, http.StatusFound) // 重定向
}
```

- 获取AccessToken：点击QQ登录后，会**回调到后台地址**，回调地址的URL中会带有code参数，根据code可以获取Access Token。
```go
func GetToken(w http.ResponseWriter, r *http.Request) {
    code := r.FormValue("code") // 获取code参数
    params := url.Values{}
    params.Add("grant_type", "authorization_code")  // 授权码验证
    params.Add("client_id", AppId)  // 将AppID传入URL
    params.Add("client_secret", AppKey)  // 将AppKey传入URL
    params.Add("code", code)  // 传入code
    str := fmt.Sprintf("%s&redirect_uri=%s", params.Encode(), redirectURI)
    loginURL := fmt.Sprintf("%s?%s", "https://graph.qq.com/oauth2.0/token", str)
    response, err := http.Get(loginURL)
    if err != nil {
    w.Write([]byte(err.Error()))
    }
    defer response.Body.Close()
    bs, _ := ioutil.ReadAll(response.Body)
    body := string(bs)
    resultMap := convertToMap(body)
    info := &PrivateInfo{}  // 获取返回内容
    info.AccessToken = resultMap["access_token"]
    info.RefreshToken = resultMap["refresh_token"]
    info.ExpiresIn = resultMap["expires_in"]
    GetOpenId(info, w)
}
```

- 获取openId：openId是每个具体用户在我们平台下的唯一标识，所有请求都会带上这个openid
```go
func GetOpenId(info *PrivateInfo, w http.ResponseWriter) {
    resp, err := http.Get(fmt.Sprintf("%s?access_token=%s", "https://graph.qq.com/oauth2.0/me", info.AccessToken))
    if err != nil {
    w.Write([]byte(err.Error()))
    }
    defer resp.Body.Close()
    bs, _ := ioutil.ReadAll(resp.Body)
    body := string(bs)
    info.OpenId = body[45:77]
    GetUserInfo(info, w)
}
```

- 获取用户信息：根据access_token和openid获取用户信息（在不访问资源的时候，这一步可以省略）
```go
func GetUserInfo(info *PrivateInfo, w http.ResponseWriter) {
  params := url.Values{}
  params.Add("access_token", info.AccessToken)
  params.Add("openid", info.OpenId)
  params.Add("oauth_consumer_key", AppId)
  uri := fmt.Sprintf("https://graph.qq.com/user/get_user_info?%s", params.Encode())
  resp, err := http.Get(uri)
  if err != nil {
  w.Write([]byte(err.Error()))
  }
  defer resp.Body.Close()
  bs, _ := ioutil.ReadAll(resp.Body)
  w.Write(bs)
}
```

- 注册应用：首先，您需要在第三方服务提供者（如QQ）的开发者平台上注册您的应用，以获取appid（应用程序ID）和appkey（应用程序密钥）。
- 构造重定向URL：用户访问您的应用时，您的应用会构造一个重定向URL，将用户引导到第三方服务提供者的登录页面。这个URL通常包含appid和重定向URI（redirect_uri），用户在第三方登录页面成功登录后，会被重定向回您的应用，并携带一个授权码（code）。
- 获取授权码：用户在第三方登录页面登录后，如果同意授权，第三方服务提供者会将用户重定向回您的应用，并在URL中附加授权码（code）。
- 交换授权码获取访问令牌：您的应用后端使用授权码、appid、appkey以及redirect_uri向第三方服务提供者的认证服务器发送请求，以交换访问令牌（access_token）和刷新令牌（refresh_token）。
- 获取用户标识：一旦您获得了访问令牌，您可以使用它来请求用户的身份信息，通常是用户的唯一标识符（如openid）。
- 使用访问令牌访问资源：有了访问令牌和用户标识符，您的应用就可以访问第三方服务提供者授权的资源了。


## 分片上传和断点续传
> **sha1值进行文件校验**
> sha1值是一种hash加密函数，常用于数据完整性验证和身份验证。唯一性、不可逆性、一致性、速度快。


### 基于TencentCOS
**文件下载**
- 创建本机缓存文件夹
- 调用COS进行下载
- 根据sha1值进行文件校验
- 设置HTTP响应头，设置Content-Disposition头和Content-Type头，提示用户下载文件
- 删除本地文件，发送文件内容给客户端

**调用COS下载流程**
```go
建立连接 设置超时时间 开启断点续传 查看API能够完成
```

**文件上传**

### 基于Minio集群
**文件下载**
- 分块下载
  - 根据FileName获取对象信息
  - 计算分块数量（`totalParts := int((info.Size + chunkSize - 1) / chunkSize)`）
  - 下载并合并文件
  - 打开合并文件并验证
  - 设置响应头并将文件内容发送给客户端

**分块下载逻辑**
- 创建channel，并发下载
```go
ch := make(chan string, totalParts)
var wg sync.WaitGroup // 并发下载
// 开启协程
for partNum := 0; partNum < totalParts; partNum++ {
    wg.Add(1)
    go l.downloadFilePart(client, bucket, object, partNum, &wg, ch)
}

// 等待所有分块下载完成
wg.Wait()

// 检查是否下载成功
close(ch)
for filePath := range ch { // 关闭之后只是防止新的值被发送到channel，已发送尚未被消费的channel依然可以被接收
  if filePath == "" {
    return fmt.Errorf("下载分块失败")
  }
}
```

- 分块下载具体逻辑
```go
// 合并分块为完成文件
func (l *DownloadMinioLogic) downloadFilePart(client *minio.Client, bucket, object string, partNumber int, wg *sync.WaitGroup, ch chan<- string) {
  defer wg.Done()
  // 创建文件保存下载的分块
  filePath := outputDir + fmt.Sprintf("part%d", partNumber)
	// 分块下载配置
	opts := minio.GetObjectOptions{}
	opts.PartNumber = partNumber

  // 下载分块
  err := client.FGetObject(context.Background(), bucket, object, filePath, opts)
  if err != nil {
    // 异常处理
    logc.Errorf(l.ctx, "下载分块失败: %v", err)
		ch <- "" // 发送空串到通道表示下载失败
		return  
  }
  ch <- filePath // 发送分块下载的文件路径到通道
}
```

- 保存合并后的文件
```go
func (l *DownloadMinioLogic) mergeFileParts(outputDir, outputFileName string, totalParts int) error {
  // 创建输出文件
  outputPath := filepath.join(outputDir, outputFileName)
  outputFile, err := os.Create(outputPath)
  defer outputFile.close()

  // 将分块内容合并到输出文件中
  for i := 0; i < totalParts; i++ {
    partPath := outputDir + fmt.Sprintf("part%d", i)
    partData, err := os.ReadFile(partPath)  // 读取partData
    _, err = outputFile.Write(partData) // 写partData
    // 删除已合并的文件
    os.Remove(partPath)
  }
}
```

**文件上传（逻辑写在rpc中）**
- 文件秒传：rpc调用，传入文件filesha1和userid，根据filesha1判断是否已存在。
```go
l.svcCtx.MysqlDb.Model(&model.File{}).Where("file_sha1 = ?", in.Filesha1).First(&file).Error; fasterr == nil {
  // 文件已存在，触发秒传
  // 构建newUserFile
  newUserFile := &model.UserFile {}
  // 查UserFile表
  l.svcCtx.MysqlDb.Create(&newUserFile)
}
```

- 分块上传
- 初始化：获取userid，文件大小，文件filesha1，rpc调用初始化。其中，分块大小为100*1024*1024，即100M。
  ```go
  // 生成分块上传的初始化信息
  uploadInfo : model.MultiPartUploadInfo{
    FileSha1:   in.FileSha1,
		FileSize:   in.FileSize,
		UploadID:   strconv.FormatInt(in.UserId, 10) + fmt.Sprintf("%x", time.Now().UnixNano()), // 根据userid+时间戳构建上传id
		ChunkSize:  100 * 1024 * 1024,
		ChunkCount: int(math.Ceil(float64(in.FileSize) / (100 * 1024 * 1024))),
  }

  // 将分块信息写入Redis
  // 写入filesha1
  if err := l.svcCtx.RedisClient.HSet(l.ctx, CacheMultipartUploadKey+uploadInfo.UploadID, "filesha1_", uploadInfo.FileSha1).Err(); err != nil {
		return nil, errors.Wrapf(errorx.NewDefaultError("redis写入错误"), "redis写入错误 err:%v", err)
	}
  // 写入filesize
	if err := l.svcCtx.RedisClient.HSet(l.ctx, CacheMultipartUploadKey+uploadInfo.UploadID, "filesize_", uploadInfo.FileSize).Err(); err != nil {
		return nil, errors.Wrapf(errorx.NewDefaultError("redis写入错误"), "redis写入错误 err:%v", err)
	}
  // 写入chunkcount
	if err := l.svcCtx.RedisClient.HSet(l.ctx, CacheMultipartUploadKey+uploadInfo.UploadID, "chunkcount_", uploadInfo.ChunkCount).Err(); err != nil {
		return nil, errors.Wrapf(errorx.NewDefaultError("redis写入错误"), "redis写入错误 err:%v", err)
	}
  ```

- 分块上传逻辑
  - api：获取Redis中分片值，如果为1，表示已经上传。如果部位1，则获取文件内容，创建缓冲区，调用rpc更新文件状态，完成上传。
  - rpc：将HSet中对应分块的值置为1，表示已经上传成功。

创建本地文件夹和文件，缓存分片内容。
```go
// api逻辑
buf := make([]byte, 1024*1024)
for {
  // 从请求的body中读取数据到缓冲区
  n, err := r.Body.Read(buf)  // 每次读取1MB数据，写入文件
  fd.Write(buf[:n])
  // 读完退出循环
  if err != nil {
    break
  }
}
```
> 为什么要创建缓冲区上传
> 

- 文件上传逻辑
1. 获取user_id
2. 接收文件流并存储到本地目录
3. 计算文件sha1值
```go
file.Seek(0, 0)
fileSha1 := utils.FileSha1(file)
file.Seek(0, 0)
```
4. 创建本地目录存储
5. 写入文件`io.Copy`
6. 使用kafka对mysql存储的文件元信息进行**异步处理**
7. 调用rpc进行上传

这里文件上传的主逻辑实现到将用户存储的文件放入服务器这一步。后续再进行文件处理。

**进行Upload的逻辑**
- COSUpload：调用TencentCOSUpload Api进行上传
- Minio：上传到Minio

在这里进行file元数据的异步处理，使用kafka
```go
err = l.batcher.Add(strconv.FormatInt(in.UserId, 10), &userfile)
```

**处理所有上传完毕的分块并合并**

在api主逻辑中实现
1. 通过uploadId查询Redis，判断是否所有分块均上传完成
2. 合并本地文件，形成一个大文件
3. 删除本地文件
4. 调用rpc将合并文件上传到对应存储
```go
result, err := l.svcCtx.RedisClient.HGetAll(l.ctx, CacheMultipartUploadKey+req.UploadID).Result()
count := 0
for k, v := range result {
  // 记录以 checkindex_ 开头且 v 为 1 的 记录的数量
  if strings.HasPrefix(k, CacheMultipartUploadIndex) && v == "1" {
			count++
	}
}

// 所需分片数量不等于从redis查出来的已完成的分片数量 无法满足合并条件

// 合并分块
// 依次读取每个分块文件，并加入到合并文件中
// 读取每个分块文件数据并加入到合并文件中
	for i := 0; i < int(req.ChunkCount); i++ {
		chunkFilePath := l.svcCtx.Config.FileLocalPath + req.UploadID + "/" + strconv.Itoa(i)
		chunkData, err := os.ReadFile(chunkFilePath)
		if err != nil {
			return errors.Wrapf(errorx.NewDefaultError(err.Error()), "os.ReadFile分块文件路径 err:%v", err)
		}

		_, err = mergedFile.Write(chunkData)
		if err != nil {
			return errors.Wrapf(errorx.NewDefaultError(err.Error()), "write分片文件内容到合并文件 err:%v", err)
		}

		// 删除已合并的分块文件
		err = os.Remove(chunkFilePath)
		if err != nil {
			logc.Error(l.ctx, "无法删除已经合并的分块文件 err:", err)
		}
	}
```

## Kafka+Batcher+Channel高并发数据处理
在uploadFileLogic中，如果同时有大量的请求，使用kafka进行流量削峰
**批量数据聚合**

在UploadFile方法中，每上传一个文件都往Kafka中发送一条消息，如果此时有大量的请求同时上传文件，会导致Kakfa中消息激增，可能会导致消息堆积、消费延迟、数据不一致、服务崩溃等问题。

之前每发送一条消息就会产生一次网络IO和磁盘IO，消息聚合后，比如聚合100条消息后再发送，此时100条消息才会产生一次网络IO和磁盘IO，能够提升吞吐量。这就是小包聚合的思想，也叫batcher或者批量处理。

这种思想随处可见，比如Mysql批量插入数据的时候，通过一条sql语句执行而不是循环一条条插入。

**如何选择聚合策略**

聚合有两个维度，分别是**聚合消息条数**和**时间**。

比如聚合100条消息就往kafka中发送一次，这个条数是可以配置的，如果一直达不到100条消息，可以通过聚合时间进行兜底。如无论目前聚合了多少条消息，只要聚合时间达到1秒，就往kafka中发送一次数据。

**批量聚合的工具Batcher**
```go
type Batcher struct {
  opts options
  Do       func(ctx context.Context, val map[string][]interface{})
  Sharding func(key string) int
  chans    []chan *msg
  wait     sync.WaitGroup
}
```

- Do方法：满足聚合条件后就会执行Do方法，其中val参数为聚合后的数据；
- Sharding方法：对key进行sharding，相同key的消息写入同一个channel中，被同一个goroutine处理；

在merge方法中有两个执行Do方法的条件：
- 聚合的数据条数大于等于设置的条数
- 触发设置的定时器

**如何使用**
- 创建Batcher对象，定义Batcher的Sharding方法和Do方法
- Sharing方法通过userid将同一用户的消息聚合到同一个goroutine中处理
- Do方法将聚合的数据一次性批量发动到Kafka

**降低消息的消费延迟**

基于批量处理的思想，提供了Bathcher工具，主要是针对生产端而言。

在消费到批量数据时，需要串行处理一条条数据，加速消费的两种方案分别是：
- 增加消费者的数量
- 在一个消费者中增加消息处理的并行度

在Kafka中，一个Topic可以配置多个Partition，数据被平均或按照生产者指定的方式写入到多个分区中。
在消费时，Kafka约定一个分区只能被一个消费者消费。

因为如果有多个Consumer同事消费一个分区的数据，在操作这个消费进度时需要加锁，对性能影响较大。

当消费者数量小于分区数量时，可以通过增加消费者的数量来提高消息处理能力，但是当消费者数量大于分区时，继续增加消费者数量就没有意义了。

所以在这里，在一个Consumer中提升消息处理的并行度，即通过多个goroutine并行消费数据。

```go
// 创建service实例
	s := &Service{
		c:        c,
		MysqlDb:  mysqlDb,
		msgsChan: make([]chan *model.NewUserFile, chanCount),
	}

	// 创建 chanCount 个消费者 goroutine
	for i := 0; i < chanCount; i++ {
		ch := make(chan *model.NewUserFile, bufferCount)
		s.msgsChan[i] = ch
		s.waiter.Add(1)
		go s.consume(ch) // 启动协程
	}
```

其中，msgsChan为slice，slice的长度为goroutine的数量。

从Kafka中消费到数据后，将数据投入goroutine中，投递消息时按照userId进行Sharding，确保对同一userId的处理是串行的。

```go
// Consumer 消费者方法用于处理消息
func (s *Service) Consumer(_ string, value string) error {
	logx.Infof("消费消息: %s\n", value)
	// 解析JSON数据为 []*model.NewUserFile 对象
	var data []*model.NewUserFile
	if err := json.Unmarshal([]byte(value), &data); err != nil {
		return err
	}

	// 将解析后的消息根据 UserId 分发到不同的通道
	for _, d := range data {
		s.msgsChan[d.UserId%chanCount] <- d
	}
	return nil
}
```