rosedb v2相对于v1的区别：
rosedb之上的Redis数据结构部分支持去掉，重写了数据文件部分，专注于轻量级KV存储引擎。

迭代器：使用迭代器遍历数据库中的所有数据，支持正向和反向迭代。
Rewind/Seek/Next/Key/Value/Close

Merge方法：回收磁盘上的无效数据，清理磁盘空间
Merge重写数据库中所有的有效数据，从而丢弃无效数据。
Merge过程中会生成Hint文件，用于存储索引，快速启动数据库。
Merge操作十分耗时，特别是在数据量较大的情况下，所以建议在数据库空闲的时候执行。

RoseDB：
基于Bitcask存储模型，轻量、快速、可靠的单机KV存储引擎。Bitcask存储模块的设计受日志结构化的文件系统和日志文件合并的启发。

Bitcask论文阅读。

RoseDB存储数据文件使用预写日志Write-Ahead-Log进行重新设计，这些日志文件是具有Block缓存的只追加写入append-only文件。

优势：
- 读写低延迟：利用Bitcask存储模型的文件追加写入特性，充分利用顺序IO优势。
- 高吞吐量：写入时不需要在磁盘上排序，Bitcask的日志结构文件设计在写入过程中减少了磁盘磁头的移动。
- 能够处理大于内存的数据集：RoseDB的数据访问设计对内存中的索引数据结构进行查找，使得数据集非常大，查找数据也非常高效。
- 一次磁盘IO可以获取任意键值对：内存索引数据结构直接指向数据所在磁盘位置，不需要多次寻址来读取一个值。归功于操作系统文件缓存以及WAL的block缓存。
- 性能快速稳定：写入操作最多需要一次打开当前文件的尾部寻址，然后进行追加写入，写入后更新内存。整个流程不会受到数据库数据量大小的影响，性能稳定。
- 崩溃恢复快速：RoseDB文件只追加写入一次，恢复操作需要检查记录并验证CRC数据，以确保数据一致性。
- 备份简单：只追加写入一次磁盘格式简化了过程，任何按照磁盘顺序归档或复制文件的工具都将正确备份或复制到RoseDB数据库。
- 批处理操作：保证原子性、一致性、持久性。（为什么不保证隔离性？）批处理操作的新写入操作在提交之前被缓存到内存中，如果批处理成功提交，则批处理所有写入操作都将持久化到磁盘，如果批处理失败，所有写入操作均会被丢弃。也就是要么全部成功，要么全部失败。

缺点：
- 所有key都需要在内存中维护。

如何恢复索引：
遍历扫描所有的数据构建，Hint文件加速过程。
Compaction：

## WAL Write Ahead Log 预写日志
一个通用需求

- [ ] Bitcask论文阅读
- [ ] 

# 1. 初识KV数据库
kv存储，即键值对存储方式。
应用场景：数据库的缓存层，分布式系统中元数据的存储、分布式锁等。
Redis：面向内存设计，持久化策略如AOF和RDB等。Redis的数据量受限于内存。
KV存储：面向磁盘设计，可以处理远超内存容量的数据，并且在性能上依然可以强悍。

数据存储模型
- B+树：BoltDB
- LSM树：充分利用顺序IO，写性能更优化，如LevelDB、RocksDB（使用最广泛，基于LevelDB，支持完善的事务处理，并发compaction，高级压缩算法等，并有更高的性能，处理较大数据时表现优异）

从0实现KV存储引擎

对数据库的基础设计有一定了解，如如何在磁盘上组织数据，如何拥有更高效的读写性能。

# 2. Bitcask论文详解
bitcask存储模型最初由一个分布式存储系统公司Riak提出，其产品包括RiakKV（NoSQL）、RiakTS(时序数据库)
- 读写低延迟
- 高吞吐，特别是对于大量的随机写入
- 能够处理超过内存容量的数据
- 崩溃恢复友好，能够保证快速恢复，尽量不丢数据
- 简单的备份和回复策略
- 相对简单、易懂的代码结构和存储格式
- 大数据量下性能有保障
- 能够自由的授权使用在Riak系统中
一个bitcask示例就是系统上的一个目录，限制同一时刻只有一个进程能够打开目录，同一时刻只有一个活跃的文件用于写入新数据。
当前活动文件写满后，就会被关闭，只能用于读取。
![[Pasted image 20240408200200.png]]
写入的数据具有固定格式
![[Pasted image 20240408200235.png]]
删除数据追加新的记录标识记录已被删除，下次merge的时候才会将无效数据清理掉。
数据文件是多条数据集合的排列。
磁盘文件写完后，会更新内存中的数据结构，叫做keydir，也就是全部key的集合，存储内容为key到一条磁盘文件数据的位置。
读取数据：先根据key在内存中找到对应的记录（chunk），这个记录记录的是磁盘中的位置（pos），然后根据这个位置找到磁盘上对应的数据文件，经过解析得到完整数据。
删除并不是删除数据，而是新增一条被标识删除的记录。
merge方法用于清理所有不可变的数据文件，
- merge操作流程
	- 遍历所有不可变的旧数据文件
	- 将有效数据重新写到新的数据文件，并将旧数据文件删掉
	- hintfile：索引文件，启动数据库时可以直接加载（加速），而不用全部加载数据文件。（hint不存储value，比数据文件小）

bitcask提供的一些面向用户的API操作接口
- Open
- Get
- Put
- Delete
- list_keys
- Fold
- Merge
- Sync 缓冲区持久化
- Close
# 3. 内存和磁盘设计
- 内存中的数据如何存放
- 磁盘中的数据如何组织
## 内存设计
内存中，需要一种支持高效插入、读取、删除数据的结构，如果需要数据高效遍历，需要选择**天然有序**的数据结构。
btree细节：google repo
常见选择：
- btree
- 跳表：SkipList
- 红黑树
- 自适应基数树：Adaptive Radix Tree 
> BTree学习

bitcask内存数据结构选择可以根据需求设计，提供一个抽象接口，可以接入不同数据结构，保证在设计上更加灵活。
## 磁盘设计
将一些标准文件操作API如read、write、close等方法进行简单封装，数据在磁盘上的读写key使用这些标准的API。
定义一个目录fio，存放文件IO相关操作的代码。 
```go
type IOManager interface {
	Read([]byte, int64) (int, err)
	Write([]byte) (int, err)
	Sync() error
	Close() error
}
```

针对数据文件的操作：目录data表示数据文件、数据项的内容
LogRecord，索引信息结构   
![[Pasted image 20240408202838.png]]

# 4. 数据读写流程
 ## 写数据流程
 - 写磁盘文件
 - 更新内存索引
将数据封装到一个结构体中，LogRecord，有三个字段Key/Value/Type
标识结构体是否为删除的
appendLogRecord方法：追加写入到数据文件方法   
![[Pasted image 20240408203637.png]]
1. 首先判断当前active文件是否存在，数据库处于初始状态时，没有任何数据文件存在。不存在则新增数据文件。
2. 进行判断，文件是否达到阈值大小。 如果达到阈值大小，需要关闭活跃文件并打开新的数据文件。如果达到阈值，还需要进行持久化操作，保证当前数据都写入到磁盘中，将活跃数据转换为旧的数据文件，并打开新的活跃文件。
3. 追加数据。
4. 调用write方法写入编码后的字节数据，write之前先记录目前活跃数据文件的写偏移量offset。
5. 如果每次写都需要进行持久化操作，调用Sync进行刷盘。
读数据流程
查找内存索引，取出位置信息 

# 5. 数据库启动流程
启动流程
- 加载数据库目录中的文件，打开文件描述符
- 遍历数据文件中的内容，构建内存索引
加载用户配置项并进行校验
定义DB结构体
加载数据文件
对应文件拓展名加载

数据文件接口
IO管理器接口
IOManager，实现基础的read，write，close，sync方法
为什么要封装？屏蔽上层调用者，不必关系底层逻辑。
打开数据文件，从数据文件中读取记录
Sync、Close方法，调用接口

# 6. 基准测试
1. 吞吐量：单位时间能够处理的请求数量
2. 响应时间：完成一个请求所需的时间
3. 并发度：系统能够同时处理的请求数量，并发度的大小慧营销到系统的稳定性和吞吐量
使用Testing框架进行测试
扩展测试：YCSB 